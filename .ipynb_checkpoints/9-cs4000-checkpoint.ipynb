{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "286ea073-f47c-40f6-83dd-94ff4f52f3a6",
   "metadata": {},
   "source": [
    "![cs4000 logo](images/cs4000.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088f332b-43c6-481e-af62-d292ef3a11e0",
   "metadata": {},
   "source": [
    "## **Course Description**\n",
    "\n",
    "\n",
    "CS 4000 - Intro to Distributed, Parallel, and Web-Centric Computing is one of the most interesting courses in the CS core cirriculum here at Ohio University. In this course you will learn about several interesting topics involving parallel and distributed computing like threading, synchronization, and potential speedup of programs. CS 4000 is a very project-based course so throughout the semester you will get plenty of hands-on learning involving the topics you will eventually learn about in lecture. Because you will be developing parallel and distributed programs on your own in this course, another essential topic you will learn about is how to calculate and optimize the efficency of your programs. Developing and optimizing programs to be as efficient as possible is a key skill you will develop in this course. Altogether, this course will definetly make you think about optimization more than you ever have before, and allow you to utilize the hardware behind the scenes to create lightning fast programs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5200a5-b7ef-4c15-b3c5-7aaea2421f86",
   "metadata": {},
   "source": [
    "## **What You'll Learn:**\n",
    "\n",
    "For this class, we are going to show you one way of developing a parallel program in C++ using a built-in library called C++ Threads. From there we are going to cover how we can calculate the efficiency of the parallel program, and also calculate the potential speed-up. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6454f746-0e84-45ca-946a-b605e888cac4",
   "metadata": {},
   "source": [
    "### **Parallel Programming with C++ Threads** \n",
    "\n",
    "C++ threads are a built-in library in the C++ language that supports multi-platform shared-memory multithreading programming in C++. What this technically means is that we can use functionality from the C++ Threads library to create C++ programs that run in parallel. A program that runs in parallel utilizes multiple computer processesors to simoultaneously carry out the calculations of a program. Instead of a normal program that only uses one of your computer's processors, a parallel program can use several at the same time! We can use C++ Threads to develop our C++ programs, and the program will tell the machine the program is running on to run it in parallel using multiple threads. Checkout the example below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b73038-2630-4535-9ff9-216861702cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>\n",
    "#include <thread>\n",
    "\n",
    "\n",
    "void call_from_thread(int tid) {\n",
    "    std::cout << \"Launched by thread \" << tid << std::endl;\n",
    "}\n",
    "static const int num_threads = 10;\n",
    "std::thread t[num_threads];\n",
    "\n",
    "//Launch a group of threads\n",
    "for (int i = 0; i < num_threads; ++i) {\n",
    "    t[i] = std::thread(call_from_thread, i);\n",
    "}\n",
    "\n",
    "//Join the threads with the main thread\n",
    "for (int i = 0; i < num_threads; ++i) {\n",
    "    t[i].join();\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737c7284-67d9-4ab2-92a6-d2360dccf435",
   "metadata": {},
   "source": [
    "If you run the above code block multiple times, you will see that the order in which each thread executes varies every time. This is because the threads are pretty unpredictable in this way. If you were to go further and break up a set of computations or calcluations, you could assign a specific set of those computations to certain threads and bring them altogether at the end to make the program execute the computations in parallel. The beauty behind this dynamic of parallelism is breaking up work into sections or 'threads', so they can execute at the same time and ultimatley speed up the program by a substantial amount."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9f7fe0-9475-48a4-98b2-17e5eaa05b51",
   "metadata": {},
   "source": [
    "### **Example 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37f1dc3-5d8c-4418-9c63-98a14da3e7a1",
   "metadata": {},
   "source": [
    "## **Conclusion:**\n",
    "Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
